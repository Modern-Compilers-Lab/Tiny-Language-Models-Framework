{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34fdf3ed-1a27-4183-b092-8c86729ba1c6",
   "metadata": {},
   "source": [
    "# Evaluating Arithmetic Operations Using Our Tiny Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75460bdd-35d6-4a66-ae88-34457ca299c4",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use our tiny language model to evaluate simple arithmetic operations in Python code snippets. The process involves loading the model, preparing the necessary metadata for character-integer mappings, and defining functions for encoding and decoding strings. We then evaluate various code examples to observe the model's generated results. This workflow highlights the capabilities of our model in executing arithmetic expressions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931d2724-c928-4ae0-a003-bfcffc587b55",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53303b76-4aa4-4a15-8e62-5e71ae5f6b5c",
   "metadata": {},
   "source": [
    "Import essential libraries for model loading, evaluation, and tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd9d1f74-2736-4219-8754-f66be4f98b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "from model import GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83b58fe-7d06-4edd-90a4-4aea840868a3",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd3f325-1bf4-4c78-a5b3-af55dee68a9c",
   "metadata": {},
   "source": [
    "Set the model name and path, and load our tiny language model into the appropriate device (CPU or GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "318cf23f-07a9-47ea-baa0-6213211dc7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): GPT(\n",
       "    (token_embedding_table): Embedding(33, 96)\n",
       "    (position_embedding_table): Embedding(256, 96)\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-5): 6 x Head(\n",
       "              (key): Linear(in_features=96, out_features=16, bias=False)\n",
       "              (query): Linear(in_features=96, out_features=16, bias=False)\n",
       "              (value): Linear(in_features=96, out_features=16, bias=False)\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=96, out_features=384, bias=False)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (3): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-5): 6 x Head(\n",
       "              (key): Linear(in_features=96, out_features=16, bias=False)\n",
       "              (query): Linear(in_features=96, out_features=16, bias=False)\n",
       "              (value): Linear(in_features=96, out_features=16, bias=False)\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=96, out_features=384, bias=False)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (3): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-5): 6 x Head(\n",
       "              (key): Linear(in_features=96, out_features=16, bias=False)\n",
       "              (query): Linear(in_features=96, out_features=16, bias=False)\n",
       "              (value): Linear(in_features=96, out_features=16, bias=False)\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=96, out_features=384, bias=False)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (3): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-5): 6 x Head(\n",
       "              (key): Linear(in_features=96, out_features=16, bias=False)\n",
       "              (query): Linear(in_features=96, out_features=16, bias=False)\n",
       "              (value): Linear(in_features=96, out_features=16, bias=False)\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=96, out_features=384, bias=False)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (3): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-5): 6 x Head(\n",
       "              (key): Linear(in_features=96, out_features=16, bias=False)\n",
       "              (query): Linear(in_features=96, out_features=16, bias=False)\n",
       "              (value): Linear(in_features=96, out_features=16, bias=False)\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=96, out_features=384, bias=False)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (3): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): Block(\n",
       "        (sa): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-5): 6 x Head(\n",
       "              (key): Linear(in_features=96, out_features=16, bias=False)\n",
       "              (query): Linear(in_features=96, out_features=16, bias=False)\n",
       "              (value): Linear(in_features=96, out_features=16, bias=False)\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=96, out_features=384, bias=False)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (3): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "    (lm_head): Linear(in_features=96, out_features=33, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"arithmetics_level1_696K\"\n",
    "model_path = os.path.join('models', f\"{model_name}.pth\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GPT()\n",
    "model = torch.compile(model)  \n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4f5be4-45ea-4893-bb97-b732cde2a906",
   "metadata": {},
   "source": [
    "## Load Tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e17dbe-14e3-4d12-a2f2-f816cbfa4c44",
   "metadata": {},
   "source": [
    "Load the metadata file containing the mappings from characters to integers and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52455912-777d-4147-ba50-413fcb452a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path = os.path.join('data', 'meta.pkl')  \n",
    "with open(meta_path, 'rb') as f:\n",
    "    meta = pickle.load(f)\n",
    "# Récuperer le mapping Caractères-Entiers\n",
    "stoi = meta['stoi']\n",
    "itos = meta['itos']\n",
    "\n",
    "# Fonctions pour la tokenisation\n",
    "def encode(s):\n",
    "    \"\"\"\n",
    "    Encode string `s` into token IDs.\n",
    "    \"\"\"\n",
    "    return [stoi[c] for c in s]\n",
    "\n",
    "def decode(l):\n",
    "    \"\"\"\n",
    "    Decode token IDs `l` into a string.\n",
    "\"\"\"\n",
    "    return ''.join([itos[i] for i in l])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6520bed8-0e5f-4df3-bba4-72828dcbf2b3",
   "metadata": {},
   "source": [
    "## Define Function to Evaluate Code Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ef6763-3c4f-4f1f-95c7-c7d29f2e536b",
   "metadata": {},
   "source": [
    "Implement a function to evaluate a given code snippet using our model, and extract the result from the model's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01cb5618-f797-43de-8ff0-e9515e18dc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour donner au modèle un extrait de code à executer \n",
    "def evaluate_example(example , max_new_tokens=22):\n",
    "    \n",
    "    encoded_example = torch.tensor(encode(example), dtype=torch.long).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        response = decode(model.generate(encoded_example, max_new_tokens=max_new_tokens)[0].tolist())\n",
    "    splited_response = response.split(\"# output\")\n",
    "    result_response = splited_response[-1]\n",
    "    generated_results = [float(match.group()) for match in re.finditer(r\"(?<=# )-?\\d+(\\.\\d+)?\", result_response.split('\\n\\n')[0].replace(\"\\n\", \"\"))]\n",
    "\n",
    "    return  generated_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440dbda2-0e84-4386-914b-6ef812f3945d",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6f6bc4c-e4c6-47e5-9cbd-f3a2f89231b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "\n",
      "a = 5\n",
      "b = 7 \n",
      "c = a * b\n",
      "print(c)\n",
      "# output\n",
      "\n",
      "Generated Result: 35.0\n"
     ]
    }
   ],
   "source": [
    "# Exemple 1\n",
    "eval_prompt_1 = \"\"\"\n",
    "a = 5\n",
    "b = 7 \n",
    "c = a * b\n",
    "print(c)\n",
    "# output\n",
    "\"\"\"\n",
    "\n",
    "print(\"Example 1:\")\n",
    "print(eval_prompt_1)\n",
    "generated_results_1 = evaluate_example(eval_prompt_1)\n",
    "print(\"Generated Result:\", generated_results_1[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7732e8c-caa5-4176-a7a5-e1599d797e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 2:\n",
      "\n",
      "e = 10\n",
      "c = 10\n",
      "a = e / c\n",
      "print(a)\n",
      "# output\n",
      "\n",
      "Generated Result: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Exemple 2\n",
    "eval_prompt_2 = \"\"\"\n",
    "e = 10\n",
    "c = 10\n",
    "a = e / c\n",
    "print(a)\n",
    "# output\n",
    "\"\"\"\n",
    "\n",
    "print(\"Example 2:\")\n",
    "print(eval_prompt_2)\n",
    "generated_results_2 = evaluate_example(eval_prompt_2)\n",
    "print(\"Generated Result:\", generated_results_2[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e2f6259-31b1-4459-bc44-de31a9fe7d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 3:\n",
      "\n",
      "a = 9\n",
      "d = 3\n",
      "d = 1\n",
      "d = 5 + 8\n",
      "print(d * 5)\n",
      "# output\n",
      "\n",
      "Generated Result: 90.0\n"
     ]
    }
   ],
   "source": [
    "# Exemple 3\n",
    "eval_prompt_3 = \"\"\"\n",
    "a = 9\n",
    "d = 3\n",
    "d = 1\n",
    "d = 5 + 8\n",
    "print(d * 5)\n",
    "# output\n",
    "\"\"\"\n",
    "\n",
    "print(\"Example 3:\")\n",
    "print(eval_prompt_3)\n",
    "generated_results_3 = evaluate_example(eval_prompt_3)\n",
    "print(\"Generated Result:\", generated_results_3[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TinyLM",
   "language": "python",
   "name": "tinylm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
