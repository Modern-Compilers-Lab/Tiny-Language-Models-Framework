{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "176621a1-0778-4a21-9de9-dd2ebefef5a6",
   "metadata": {},
   "source": [
    "# Evaluating Arithmetic Operations Using Our Finetuned Large Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d10bd3-660c-43df-9719-43fa71b119ea",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use our fine-tuned Code Llama model to evaluate simple arithmetic operations in Python code snippets. The process involves loading the pre-trained model, preparing the tokenizer, and defining functions to evaluate code examples. We then evaluate various code snippets to observe the model's generated results. This workflow highlights the capabilities of the Code Llama model in executing arithmetic expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac948737-336a-4d73-ba56-64601000e561",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7654d2f3-bae2-4936-b86c-a5a6b0e2ed51",
   "metadata": {},
   "source": [
    "Import essential libraries for model loading, evaluation, and tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c3d4f58-731a-47a8-9121-4689acc8e2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import transformers\n",
    "\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd801aa-d88d-42b0-bfac-3901489f7642",
   "metadata": {},
   "source": [
    "## Load the Pre-trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74874a67-6e25-4395-81fa-768c630db298",
   "metadata": {},
   "source": [
    "Load the pre-trained Code Llama model in 8-bit precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1d25be0-8aed-4825-976f-f066aa45eb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7fc7c9fd3b422fa5413277b16ac29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Charger le modèle pré-entraîné\n",
    "base_model = \"codellama/CodeLlama-7b-hf\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3987ca4f-b25d-4d9d-9dc2-79c4beeb7917",
   "metadata": {},
   "source": [
    "## Load the Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f5cdc6-48f6-4765-8c7c-76ba6a47e5e4",
   "metadata": {},
   "source": [
    "Load the tokenizer corresponding to the pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7fb73a7-d643-4c31-866e-d34baf0dbff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b475a-8667-4d52-b028-ac04ec129746",
   "metadata": {},
   "source": [
    "## Load the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fa550a-8c96-4549-a496-de5d6c3215e6",
   "metadata": {},
   "source": [
    "Load the fine-tuned model from the checkpoint directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17bc03cf-634d-460d-806f-ce1ff8bf6d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"models/code-llama-finetuned-level1\"\n",
    "model = PeftModel.from_pretrained(model, checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa98af7-89d9-4a16-b266-18fae4cd12b9",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6d2155d-0d2c-4c6b-a438-d4e976e5f49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a = 9\n",
      "b = 7 \n",
      "c = a * b\n",
      "print(c)\n",
      "# output\n",
      "# 63\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"\n",
    "a = 9\n",
    "b = 7 \n",
    "c = a * b\n",
    "print(c)\n",
    "# output\n",
    "\"\"\"\n",
    "\n",
    "# Tokeniser l'invite d'évaluation\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Évaluer le modèle\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = tokenizer.decode(model.generate(**model_input, max_new_tokens=30, pad_token_id=tokenizer.eos_token_id)[0], skip_special_tokens=True)\n",
    "\n",
    "# Afficher le résultat\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edabaa2f-3170-48fb-b45e-43c1fd7d5cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "e = 10\n",
      "c = 10\n",
      "a = e / c\n",
      "print(a)\n",
      "# output\n",
      "# 1.0\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"\n",
    "e = 10\n",
    "c = 10\n",
    "a = e / c\n",
    "print(a)\n",
    "# output\n",
    "\"\"\"\n",
    "\n",
    "# Tokeniser l'invite d'évaluation\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Évaluer le modèle\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = tokenizer.decode(model.generate(**model_input, max_new_tokens=30, pad_token_id=tokenizer.eos_token_id)[0], skip_special_tokens=True)\n",
    "\n",
    "# Afficher le résultat\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4e818ed-27c1-4bd0-b1fe-35610851cc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a = 9\n",
      "d = 3\n",
      "d = 1\n",
      "d = 5 + 8\n",
      "print(d * 5)\n",
      "# output\n",
      "# 45\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"\n",
    "a = 9\n",
    "d = 3\n",
    "d = 1\n",
    "d = 5 + 8\n",
    "print(d * 5)\n",
    "# output\n",
    "\"\"\"\n",
    "\n",
    "# Tokeniser l'invite d'évaluation\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Évaluer le modèle\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = tokenizer.decode(model.generate(**model_input, max_new_tokens=30, pad_token_id=tokenizer.eos_token_id)[0], skip_special_tokens=True)\n",
    "\n",
    "# Afficher le résultat\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TinyLM",
   "language": "python",
   "name": "tinylm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
