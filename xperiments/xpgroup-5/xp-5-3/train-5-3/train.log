|ITERS: 280105 / 280105 | EPOCHS: 1.70 | COMP: 100.00% | RATE: 1.58 it./s | SPD: 0.6320 s/it.| ERT: (0, 0, 0, 0) | ET: (2, 6, 15, 9)                                                                    
val>|ITERS: 500 / 500 | COMP: 100.00% | RATE: 3.23 it./s | SPD: 0.3092 s/it.| ERT: (0, 0, 0, 0) |                                                                                                       

Finished setup:

Initilizaing neptune:
	--> neptune init
	--> saving the neptune runid

Set the random seed for reproducibility:

Setting the device to GPU if available, otherwise CPU:
	--> device set to cuda:6.

Setting arch-hyperparams for the GPT model:

Loading the training and evaluation data:
	--> loading train.bin
	--> took (0, 0, 0, 2)
	--> loading val.bin
	--> took (0, 0, 0, 0)

Setting train-hyperparams and util variables:

Defining the model and utilities:

The model:
	--> def human readable

Creating the model:

The model has 11M trainable parameters:
	--> initialiazing the optimizer
	--> initializing the learing rate scheduler
	--> computing the initial loss
	--> saving the last loss for early stopping
	--> neptune logging the initial loss

==========================================================================================:

2024-12-25_04-27 : iter     0 <=> epoch 0 | train loss 4.4762 | val loss 4.4769:
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-25_05-41 : iter       5000 <=> epoch 0.03034569607489873 | train loss 0.4086254537 | val loss 0.4056553543
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-25_06-39 : iter      10000 <=> epoch 0.06069139214979746 | train loss 0.3687662482 | val loss 0.3691122234
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-25_07-37 : iter      15000 <=> epoch 0.0910370882246962 | train loss 0.3502811790 | val loss 0.3528611362
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-25_08-35 : iter      20000 <=> epoch 0.12138278429959493 | train loss 0.3393034637 | val loss 0.3452213705
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-25_09-32 : iter      25000 <=> epoch 0.15172848037449366 | train loss 0.3310492337 | val loss 0.3434959948
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-25_10-30 : iter      30000 <=> epoch 0.1820741764493924 | train loss 0.3258166015 | val loss 0.3417131007
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-25_11-28 : iter      35000 <=> epoch 0.21241987252429112 | train loss 0.3222308755 | val loss 0.3375303149
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-25_12-26 : iter      40000 <=> epoch 0.24276556859918985 | train loss 0.3160416186 | val loss 0.3364129066
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-25_13-24 : iter      45000 <=> epoch 0.2731112646740886 | train loss 0.3140796125 | val loss 0.3377335370
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-25_14-21 : iter      50000 <=> epoch 0.3034569607489873 | train loss 0.3091689348 | val loss 0.3390751779
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-25_15-19 : iter      55000 <=> epoch 0.33380265682388605 | train loss 0.3068613708 | val loss 0.3383275568
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-25_16-17 : iter      60000 <=> epoch 0.3641483528987848 | train loss 0.3053408563 | val loss 0.3366790712
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-25_17-15 : iter      65000 <=> epoch 0.3944940489736835 | train loss 0.3035358489 | val loss 0.3405008018
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-25_18-13 : iter      70000 <=> epoch 0.42483974504858224 | train loss 0.2993407845 | val loss 0.3412027657
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-25_19-11 : iter      75000 <=> epoch 0.45518544112348097 | train loss 0.2990232110 | val loss 0.3379360437
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-25_20-09 : iter      80000 <=> epoch 0.4855311371983797 | train loss 0.2961824238 | val loss 0.3380414248
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-25_21-06 : iter      85000 <=> epoch 0.5158768332732784 | train loss 0.2952581346 | val loss 0.3450751901
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-25_22-04 : iter      90000 <=> epoch 0.5462225293481772 | train loss 0.2931464016 | val loss 0.3440599442
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-25_23-02 : iter      95000 <=> epoch 0.5765682254230758 | train loss 0.2921269536 | val loss 0.3417357802
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_00-00 : iter     100000 <=> epoch 0.6069139214979746 | train loss 0.2901760340 | val loss 0.3434981108
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_00-58 : iter     105000 <=> epoch 0.6372596175728733 | train loss 0.2905549109 | val loss 0.3440454602
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_01-55 : iter     110000 <=> epoch 0.6676053136477721 | train loss 0.2890963554 | val loss 0.3437949419
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_02-53 : iter     115000 <=> epoch 0.6979510097226708 | train loss 0.2879989445 | val loss 0.3464133441
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_03-51 : iter     120000 <=> epoch 0.7282967057975696 | train loss 0.2875419259 | val loss 0.3419914246
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_04-49 : iter     125000 <=> epoch 0.7586424018724682 | train loss 0.2860608995 | val loss 0.3490737379
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_05-47 : iter     130000 <=> epoch 0.788988097947367 | train loss 0.2841825187 | val loss 0.3429570794
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_06-44 : iter     135000 <=> epoch 0.8193337940222657 | train loss 0.2842396498 | val loss 0.3454796374
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_07-42 : iter     140000 <=> epoch 0.8496794900971645 | train loss 0.2829474211 | val loss 0.3497127295
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_08-40 : iter     145000 <=> epoch 0.8800251861720632 | train loss 0.2810719907 | val loss 0.3452044725
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_09-38 : iter     150000 <=> epoch 0.9103708822469619 | train loss 0.2818847895 | val loss 0.3444861472
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_10-35 : iter     155000 <=> epoch 0.9407165783218606 | train loss 0.2811376452 | val loss 0.3449676633
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_11-33 : iter     160000 <=> epoch 0.9710622743967594 | train loss 0.2809410393 | val loss 0.3494069576
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_12-31 : iter     165000 <=> epoch 1.001407970471658 | train loss 0.2806970477 | val loss 0.3414088190
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_13-29 : iter     170000 <=> epoch 1.0317536665465568 | train loss 0.2792697847 | val loss 0.3419762552
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_14-27 : iter     175000 <=> epoch 1.0620993626214557 | train loss 0.2792187035 | val loss 0.3420167267
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_15-24 : iter     180000 <=> epoch 1.0924450586963543 | train loss 0.2792758346 | val loss 0.3527313173
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_16-22 : iter     185000 <=> epoch 1.122790754771253 | train loss 0.2794676125 | val loss 0.3460921049
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_17-20 : iter     190000 <=> epoch 1.1531364508461517 | train loss 0.2786101699 | val loss 0.3473952711
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_18-18 : iter     195000 <=> epoch 1.1834821469210506 | train loss 0.2775835097 | val loss 0.3480807543
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_19-16 : iter     200000 <=> epoch 1.2138278429959493 | train loss 0.2662436664 | val loss 0.3515361547
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_20-13 : iter     205000 <=> epoch 1.244173539070848 | train loss 0.2632727027 | val loss 0.3502089381
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_21-11 : iter     210000 <=> epoch 1.2745192351457466 | train loss 0.2620625794 | val loss 0.3552672863
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_22-09 : iter     215000 <=> epoch 1.3048649312206455 | train loss 0.2604968250 | val loss 0.3582899570
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-26_23-07 : iter     220000 <=> epoch 1.3352106272955442 | train loss 0.2598456740 | val loss 0.3609324396
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-27_00-05 : iter     225000 <=> epoch 1.3655563233704429 | train loss 0.2591058612 | val loss 0.3594760597
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-27_01-03 : iter     230000 <=> epoch 1.3959020194453415 | train loss 0.2584591806 | val loss 0.3579784632
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-27_02-01 : iter     235000 <=> epoch 1.4262477155202404 | train loss 0.2586351633 | val loss 0.3602258861
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-27_02-59 : iter     240000 <=> epoch 1.456593411595139 | train loss 0.2584278584 | val loss 0.3630073071
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-27_03-57 : iter     245000 <=> epoch 1.4869391076700378 | train loss 0.2584576309 | val loss 0.3606708944
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-27_04-54 : iter     250000 <=> epoch 1.5172848037449365 | train loss 0.2585904896 | val loss 0.3617819846
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-27_05-52 : iter     255000 <=> epoch 1.5476304998198354 | train loss 0.2583374977 | val loss 0.3601446450
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-27_06-50 : iter     260000 <=> epoch 1.577976195894734 | train loss 0.2583080232 | val loss 0.3613559604
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-27_07-48 : iter     265000 <=> epoch 1.6083218919696327 | train loss 0.2570778430 | val loss 0.3613265157
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-27_08-46 : iter     270000 <=> epoch 1.6386675880445314 | train loss 0.2575088739 | val loss 0.3610683680
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-27_09-44 : iter     275000 <=> epoch 1.6690132841194303 | train loss 0.2578607798 | val loss 0.3600198030
	--> training ...
	--> checkpointing
	--> checkpoint_2024-12-27_10-41 : iter     280000 <=> epoch 1.699358980194329 | train loss 0.2568314075 | val loss 0.3619546890
	--> training ...
