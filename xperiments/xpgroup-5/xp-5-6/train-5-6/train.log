|BATCH_LOSS: 0.00614 | TPS:  1074351 tokens/sec. | ITERS: 40085 / 40085 | EPOCHS: 1.70 | COMP: 100.00% | RATE: 6.56 it./s | SPD: 152.5013 ms/it.| ERT: (0, 0, 0, 0) | ET: (0, 2, 16, 46)                
val>|ITERS: 100 / 100 | COMP: 100.00% | RATE: 7.28 it./s | SPD: 0.1374 s/it.| ERT: (0, 0, 0, 0) | ET: (0, 0, 0, 27)                                                                                     

vocab_size: 67

Loading train.bin

took (0, 0, 0, 3)

Loading val.bin

took (0, 0, 0, 0)

Compiling the model... (takes a ~minute)

Evaluating initial loss

INITIAL LOSS: train loss 4.3364882469 | val loss 4.3364186287

INIT ITER TIME: 1250.7143483161926

INIT ITER TIME: 14.481357097625732

INIT ITER TIME: 0.18239927291870117

INIT ITER TIME: 0.15281462669372559

INIT ITER TIME: 0.15268731117248535

INIT ITER TIME: 0.15259432792663574

INIT ITER TIME: 0.15261149406433105

INIT ITER TIME: 0.15722918510437012

INIT ITER TIME: 0.15250158309936523

INIT ITER TIME: 0.15273165702819824

INIT ITER TIME: 0.15272736549377441

INIT ITER TIME: 0.15262269973754883

INIT ITER TIME: 0.1527397632598877

INIT ITER TIME: 0.15331435203552246

INIT ITER TIME: 0.15261602401733398

INIT ITER TIME: 0.15262842178344727

INIT ITER TIME: 0.15261578559875488

INIT ITER TIME: 0.15256857872009277

INIT ITER TIME: 0.15276265144348145

INIT ITER TIME: 0.15309453010559082

checkpoint_2025-01-06_03-52 : iter       2000 | epoch 0.08 | train loss 2.5333199501 | val loss 2.5343897343


checkpoint_2025-01-06_03-58 : iter       4000 | epoch 0.17 | train loss 1.1039091349 | val loss 1.1056734324


checkpoint_2025-01-06_04-03 : iter       6000 | epoch 0.25 | train loss 1.0799180269 | val loss 1.0777966976


checkpoint_2025-01-06_04-09 : iter       8000 | epoch 0.34 | train loss 1.0682400465 | val loss 1.0670799017


checkpoint_2025-01-06_04-15 : iter      10000 | epoch 0.42 | train loss 1.0557636023 | val loss 1.0566601753


checkpoint_2025-01-06_04-21 : iter      12000 | epoch 0.51 | train loss 1.0366301537 | val loss 1.0388952494


checkpoint_2025-01-06_04-27 : iter      14000 | epoch 0.59 | train loss 1.0267930031 | val loss 1.0265326500


checkpoint_2025-01-06_04-32 : iter      16000 | epoch 0.68 | train loss 1.0190631151 | val loss 1.0197566748


checkpoint_2025-01-06_04-38 : iter      18000 | epoch 0.76 | train loss 1.0148348808 | val loss 1.0163216591


checkpoint_2025-01-06_04-44 : iter      20000 | epoch 0.85 | train loss 1.0118894577 | val loss 1.0118445158


checkpoint_2025-01-06_04-49 : iter      22000 | epoch 0.93 | train loss 1.0099956989 | val loss 1.0090758801


checkpoint_2025-01-06_04-55 : iter      24000 | epoch 1.02 | train loss 3.3655734062 | val loss 3.3677501678


checkpoint_2025-01-06_05-01 : iter      26000 | epoch 1.10 | train loss 3.7171447277 | val loss 3.7166755199


checkpoint_2025-01-06_05-07 : iter      28000 | epoch 1.19 | train loss 3.9310283661 | val loss 3.9364762306


checkpoint_2025-01-06_05-13 : iter      30000 | epoch 1.27 | train loss 3.9923815727 | val loss 3.9817130566


checkpoint_2025-01-06_05-18 : iter      32000 | epoch 1.36 | train loss 4.0837116241 | val loss 4.0756325722


checkpoint_2025-01-06_05-24 : iter      34000 | epoch 1.44 | train loss 4.1168613434 | val loss 4.1072788239


checkpoint_2025-01-06_05-30 : iter      36000 | epoch 1.53 | train loss 4.1451463699 | val loss 4.1487169266


checkpoint_2025-01-06_05-36 : iter      38000 | epoch 1.61 | train loss 4.1490111351 | val loss 4.1489486694


checkpoint_2025-01-06_05-42 : iter      40000 | epoch 1.70 | train loss 4.1555352211 | val loss 4.1499977112

