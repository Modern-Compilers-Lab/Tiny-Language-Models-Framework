|ITERS: 1728355 / 5548507 | COMP: 31.15% | RATE: 2.20 it./s | SPD: 0.4555 s/it.| ERT: (20, 3, 20, 49)                                                                                                   
val>|ITERS: 500 / 500 | COMP: 100.00% | RATE: 6.64 it./s | SPD: 0.1505 s/it.| ERT: (0, 0, 0, 0) |                                                                                                       

Importing ...:
	--> took (0, 0, 0, 1)

Starting the netpune logging:
	--> neptune init
	--> saving the runid

Set the random seed for reproducibility:

Set the device to GPU if available, otherwise CPU:
	--> device set to cuda:1.

Setting arch-hyperparams for the GPT model:

Loading the training and evaluation data:
	--> train.bin
	--> took (0, 0, 0, 17)
	--> val.bin
	--> took (0, 0, 0, 10)

Setting train-hyperparams and util variables:
	--> max_iters = 5548507

Defining the model and utilities:

The model:
	--> def get random batch of data
	--> def estimate loss
	--> def human readable

Loading the meta object:
	--> loading
	--> setting vocab size

Creating the model:

The model has 61M trainable parameters:

Preparing for the training loop:
	--> initialiazing the optimizer
	--> initializing the learing rate scheduler
	--> computing the initial loss
	--> saving the last loss for early stopping
	--> neptune logging the initial loss

Training loop:

==========================================================================================:

2024-10-07_15-46 : iter     0 <=> epoch 0 | train loss 4.2228 | val loss 4.2227:
	--> training ...
	--> checkpointing ...

2024-10-07_16-27 : iter       5000 <=> epoch 0.0027034298380463418 | train loss 1.0774635077 | val loss 1.0769591331:
	--> training ...
	--> checkpointing ...

2024-10-07_17-07 : iter      10000 <=> epoch 0.0054068596760926835 | train loss 0.9189907312 | val loss 0.9202371240:
	--> training ...
	--> checkpointing ...

2024-10-07_17-48 : iter      15000 <=> epoch 0.008110289514139026 | train loss 0.9287022948 | val loss 0.9290140271:
	--> training ...
	--> checkpointing ...

2024-10-07_18-28 : iter      20000 <=> epoch 0.010813719352185367 | train loss 0.8986858726 | val loss 0.8997752666:
	--> training ...
	--> checkpointing ...

2024-10-07_19-09 : iter      25000 <=> epoch 0.01351714919023171 | train loss 0.9200282693 | val loss 0.9223675728:
	--> training ...
	--> checkpointing ...

2024-10-07_19-49 : iter      30000 <=> epoch 0.016220579028278052 | train loss 0.9242451787 | val loss 0.9263104796:
	--> training ...
	--> checkpointing ...

2024-10-07_20-30 : iter      35000 <=> epoch 0.018924008866324393 | train loss 0.8944302797 | val loss 0.8956977129:
	--> training ...
	--> checkpointing ...

2024-10-07_21-10 : iter      40000 <=> epoch 0.021627438704370734 | train loss 0.8890901208 | val loss 0.8880913258:
	--> training ...
	--> checkpointing ...

2024-10-07_21-51 : iter      45000 <=> epoch 0.024330868542417075 | train loss 0.8561232090 | val loss 0.8569018841:
	--> training ...
	--> checkpointing ...

2024-10-07_22-32 : iter      50000 <=> epoch 0.02703429838046342 | train loss 0.8544388413 | val loss 0.8533070683:
	--> training ...
	--> checkpointing ...

2024-10-07_23-12 : iter      55000 <=> epoch 0.02973772821850976 | train loss 0.8329613209 | val loss 0.8338111043:
	--> training ...
	--> checkpointing ...

2024-10-07_23-53 : iter      60000 <=> epoch 0.032441158056556105 | train loss 0.8277426362 | val loss 0.8282198310:
	--> training ...
	--> checkpointing ...

2024-10-08_00-33 : iter      65000 <=> epoch 0.035144587894602446 | train loss 0.8548075557 | val loss 0.8527075648:
	--> training ...
	--> checkpointing ...

2024-10-08_01-14 : iter      70000 <=> epoch 0.03784801773264879 | train loss 0.8253608942 | val loss 0.8242087960:
	--> training ...
	--> checkpointing ...

2024-10-08_01-54 : iter      75000 <=> epoch 0.04055144757069513 | train loss 0.8136080503 | val loss 0.8129460216:
	--> training ...
	--> checkpointing ...

2024-10-08_02-35 : iter      80000 <=> epoch 0.04325487740874147 | train loss 0.8019659519 | val loss 0.8004590273:
	--> training ...
	--> checkpointing ...

2024-10-08_03-16 : iter      85000 <=> epoch 0.04595830724678781 | train loss 0.7876884937 | val loss 0.7878266573:
	--> training ...
	--> checkpointing ...

2024-10-08_03-56 : iter      90000 <=> epoch 0.04866173708483415 | train loss 0.7972139716 | val loss 0.7964567542:
	--> training ...
	--> checkpointing ...

2024-10-08_04-37 : iter      95000 <=> epoch 0.0513651669228805 | train loss 0.7826346159 | val loss 0.7821522355:
	--> training ...
	--> checkpointing ...

2024-10-08_05-17 : iter     100000 <=> epoch 0.05406859676092684 | train loss 0.7967829108 | val loss 0.7996296287:
	--> training ...
	--> checkpointing ...

2024-10-08_05-58 : iter     105000 <=> epoch 0.05677202659897318 | train loss 0.8272575736 | val loss 0.8304597139:
	--> training ...
	--> checkpointing ...

2024-10-08_06-39 : iter     110000 <=> epoch 0.05947545643701952 | train loss 0.7919982076 | val loss 0.7891896963:
	--> training ...
	--> checkpointing ...

2024-10-08_07-19 : iter     115000 <=> epoch 0.06217888627506586 | train loss 0.8297640085 | val loss 0.8288124800:
	--> training ...
	--> checkpointing ...

2024-10-08_08-00 : iter     120000 <=> epoch 0.06488231611311221 | train loss 0.8463374376 | val loss 0.8459897041:
	--> training ...
	--> checkpointing ...

2024-10-08_08-41 : iter     125000 <=> epoch 0.06758574595115854 | train loss 0.7960808277 | val loss 0.7958341241:
	--> training ...
	--> checkpointing ...

2024-10-08_09-21 : iter     130000 <=> epoch 0.07028917578920489 | train loss 0.7990629673 | val loss 0.8026219606:
	--> training ...
	--> checkpointing ...

2024-10-08_10-02 : iter     135000 <=> epoch 0.07299260562725123 | train loss 0.8080648184 | val loss 0.8065832257:
	--> training ...
	--> checkpointing ...

2024-10-08_10-43 : iter     140000 <=> epoch 0.07569603546529757 | train loss 0.7695607543 | val loss 0.7703736424:
	--> training ...
	--> checkpointing ...

2024-10-08_11-23 : iter     145000 <=> epoch 0.07839946530334391 | train loss 0.7665925622 | val loss 0.7668911219:
	--> training ...
	--> checkpointing ...

2024-10-08_12-04 : iter     150000 <=> epoch 0.08110289514139025 | train loss 0.7539223433 | val loss 0.7543976307:
	--> training ...
	--> checkpointing ...

2024-10-08_12-45 : iter     155000 <=> epoch 0.0838063249794366 | train loss 0.7430780530 | val loss 0.7445237041:
	--> training ...
	--> checkpointing ...

2024-10-08_13-26 : iter     160000 <=> epoch 0.08650975481748294 | train loss 0.7528871894 | val loss 0.7541392446:
	--> training ...
	--> checkpointing ...

2024-10-08_14-06 : iter     165000 <=> epoch 0.08921318465552928 | train loss 0.7435732484 | val loss 0.7422260642:
	--> training ...
	--> checkpointing ...

2024-10-08_14-47 : iter     170000 <=> epoch 0.09191661449357562 | train loss 0.8227741718 | val loss 0.8221188784:
	--> training ...
	--> checkpointing ...

2024-10-08_15-28 : iter     175000 <=> epoch 0.09462004433162197 | train loss 0.7411949039 | val loss 0.7398602962:
	--> training ...
	--> checkpointing ...

2024-10-08_16-09 : iter     180000 <=> epoch 0.0973234741696683 | train loss 0.7046766877 | val loss 0.7031328082:
	--> training ...
	--> checkpointing ...

2024-10-08_16-49 : iter     185000 <=> epoch 0.10002690400771465 | train loss 0.6872649193 | val loss 0.6869594455:
	--> training ...
	--> checkpointing ...

2024-10-08_17-30 : iter     190000 <=> epoch 0.102730333845761 | train loss 0.6709232926 | val loss 0.6706100106:
	--> training ...
	--> checkpointing ...

2024-10-08_18-11 : iter     195000 <=> epoch 0.10543376368380733 | train loss 0.6634125710 | val loss 0.6638939381:
	--> training ...
	--> checkpointing ...

2024-10-08_18-52 : iter     200000 <=> epoch 0.10813719352185368 | train loss 0.6536071897 | val loss 0.6537019610:
	--> training ...
	--> checkpointing ...

2024-10-08_19-33 : iter     205000 <=> epoch 0.11084062335990001 | train loss 0.6489365101 | val loss 0.6484978199:
	--> training ...
	--> checkpointing ...

2024-10-08_20-13 : iter     210000 <=> epoch 0.11354405319794636 | train loss 0.6427330971 | val loss 0.6432132721:
	--> training ...
	--> checkpointing ...

2024-10-08_20-54 : iter     215000 <=> epoch 0.1162474830359927 | train loss 0.6419301033 | val loss 0.6405442953:
	--> training ...
	--> checkpointing ...

2024-10-08_21-35 : iter     220000 <=> epoch 0.11895091287403904 | train loss 0.6384327412 | val loss 0.6374824643:
	--> training ...
	--> checkpointing ...

2024-10-08_22-16 : iter     225000 <=> epoch 0.12165434271208539 | train loss 0.6353329420 | val loss 0.6335021853:
	--> training ...
	--> checkpointing ...

2024-10-08_22-57 : iter     230000 <=> epoch 0.12435777255013172 | train loss 0.6324238181 | val loss 0.6317114234:
	--> training ...
	--> checkpointing ...

2024-10-08_23-38 : iter     235000 <=> epoch 0.12706120238817806 | train loss 0.6308676600 | val loss 0.6299141049:
	--> training ...
	--> checkpointing ...

2024-10-09_00-18 : iter     240000 <=> epoch 0.12976463222622442 | train loss 0.6277759075 | val loss 0.6282158494:
	--> training ...
	--> checkpointing ...

2024-10-09_00-59 : iter     245000 <=> epoch 0.13246806206427075 | train loss 0.6271997094 | val loss 0.6262930036:
	--> training ...
	--> checkpointing ...

2024-10-09_01-40 : iter     250000 <=> epoch 0.1351714919023171 | train loss 0.6236909032 | val loss 0.6250584722:
	--> training ...
	--> checkpointing ...

2024-10-09_02-21 : iter     255000 <=> epoch 0.13787492174036342 | train loss 0.6239449382 | val loss 0.6213784814:
	--> training ...
	--> checkpointing ...

2024-10-09_03-02 : iter     260000 <=> epoch 0.14057835157840978 | train loss 0.6217154264 | val loss 0.6196804643:
	--> training ...
	--> checkpointing ...

2024-10-09_03-42 : iter     265000 <=> epoch 0.14328178141645612 | train loss 0.6190906167 | val loss 0.6197764277:
	--> training ...
	--> checkpointing ...

2024-10-09_04-23 : iter     270000 <=> epoch 0.14598521125450245 | train loss 0.6178598404 | val loss 0.6172277927:
	--> training ...
	--> checkpointing ...

2024-10-09_05-04 : iter     275000 <=> epoch 0.1486886410925488 | train loss 0.6156772375 | val loss 0.6194952130:
	--> training ...
	--> checkpointing ...

2024-10-09_05-45 : iter     280000 <=> epoch 0.15139207093059515 | train loss 0.6154763103 | val loss 0.6158673167:
	--> training ...
	--> checkpointing ...

2024-10-09_06-25 : iter     285000 <=> epoch 0.15409550076864148 | train loss 0.6137060523 | val loss 0.6144540906:
	--> training ...
	--> checkpointing ...

2024-10-09_07-06 : iter     290000 <=> epoch 0.15679893060668781 | train loss 0.6129399538 | val loss 0.6123958826:
	--> training ...
	--> checkpointing ...

2024-10-09_07-47 : iter     295000 <=> epoch 0.15950236044473418 | train loss 0.6099259853 | val loss 0.6124029756:
	--> training ...
	--> checkpointing ...

2024-10-09_08-27 : iter     300000 <=> epoch 0.1622057902827805 | train loss 0.6113731861 | val loss 0.6110150814:
	--> training ...
	--> checkpointing ...

2024-10-09_09-08 : iter     305000 <=> epoch 0.16490922012082684 | train loss 0.6103603244 | val loss 0.6107701659:
	--> training ...
	--> checkpointing ...

2024-10-09_09-49 : iter     310000 <=> epoch 0.1676126499588732 | train loss 0.6101484299 | val loss 0.6095558405:
	--> training ...
	--> checkpointing ...

2024-10-09_10-30 : iter     315000 <=> epoch 0.17031607979691954 | train loss 0.6092001200 | val loss 0.6073744893:
	--> training ...
	--> checkpointing ...

2024-10-09_11-10 : iter     320000 <=> epoch 0.17301950963496587 | train loss 0.6074147820 | val loss 0.6087741852:
	--> training ...
	--> checkpointing ...

2024-10-09_11-51 : iter     325000 <=> epoch 0.1757229394730122 | train loss 0.6071600318 | val loss 0.6071928144:
	--> training ...
	--> checkpointing ...

2024-10-09_12-32 : iter     330000 <=> epoch 0.17842636931105857 | train loss 0.6070418954 | val loss 0.6054697037:
	--> training ...
	--> checkpointing ...

2024-10-09_13-12 : iter     335000 <=> epoch 0.1811297991491049 | train loss 0.6062225103 | val loss 0.6054150462:
	--> training ...
	--> checkpointing ...

2024-10-09_13-53 : iter     340000 <=> epoch 0.18383322898715124 | train loss 0.6060401201 | val loss 0.6054170132:
	--> training ...
	--> checkpointing ...

2024-10-09_14-34 : iter     345000 <=> epoch 0.1865366588251976 | train loss 0.6043905616 | val loss 0.6051428318:
	--> training ...
	--> checkpointing ...

2024-10-09_15-14 : iter     350000 <=> epoch 0.18924008866324393 | train loss 0.6053990126 | val loss 0.6036998630:
	--> training ...
	--> checkpointing ...

2024-10-09_15-55 : iter     355000 <=> epoch 0.19194351850129027 | train loss 0.6038647294 | val loss 0.6037755013:
	--> training ...
	--> checkpointing ...

2024-10-09_16-35 : iter     360000 <=> epoch 0.1946469483393366 | train loss 0.6041985750 | val loss 0.6046051383:
	--> training ...
	--> checkpointing ...

2024-10-09_17-16 : iter     365000 <=> epoch 0.19735037817738296 | train loss 0.6028093100 | val loss 0.6040804386:
	--> training ...
	--> checkpointing ...

2024-10-09_17-56 : iter     370000 <=> epoch 0.2000538080154293 | train loss 0.6037726998 | val loss 0.6033747196:
	--> training ...
	--> checkpointing ...

2024-10-09_18-37 : iter     375000 <=> epoch 0.20275723785347563 | train loss 0.6036082506 | val loss 0.6032296419:
	--> training ...
	--> checkpointing ...

2024-10-09_19-17 : iter     380000 <=> epoch 0.205460667691522 | train loss 0.6023881435 | val loss 0.6045397520:
	--> training ...
	--> checkpointing ...

2024-10-09_19-58 : iter     385000 <=> epoch 0.20816409752956833 | train loss 0.6011984944 | val loss 0.6011347175:
	--> training ...
	--> checkpointing ...

2024-10-09_20-38 : iter     390000 <=> epoch 0.21086752736761466 | train loss 0.6021535993 | val loss 0.6013667583:
	--> training ...
	--> checkpointing ...

2024-10-09_21-19 : iter     395000 <=> epoch 0.213570957205661 | train loss 0.6023897529 | val loss 0.6003618836:
	--> training ...
	--> checkpointing ...

2024-10-09_21-59 : iter     400000 <=> epoch 0.21627438704370736 | train loss 0.6022430062 | val loss 0.6028805971:
	--> training ...
	--> checkpointing ...

2024-10-09_22-40 : iter     405000 <=> epoch 0.2189778168817537 | train loss 0.6017707586 | val loss 0.6004632711:
	--> training ...
	--> checkpointing ...

2024-10-09_23-20 : iter     410000 <=> epoch 0.22168124671980002 | train loss 0.6011270285 | val loss 0.6006423235:
	--> training ...
	--> checkpointing ...

2024-10-10_00-01 : iter     415000 <=> epoch 0.22438467655784639 | train loss 0.6020073295 | val loss 0.6004446745:
	--> training ...
	--> checkpointing ...

2024-10-10_00-41 : iter     420000 <=> epoch 0.22708810639589272 | train loss 0.6007161736 | val loss 0.6007988453:
	--> training ...
	--> checkpointing ...

2024-10-10_01-22 : iter     425000 <=> epoch 0.22979153623393905 | train loss 0.6018073559 | val loss 0.6008889675:
	--> training ...
	--> checkpointing ...

2024-10-10_02-02 : iter     430000 <=> epoch 0.2324949660719854 | train loss 0.6006835699 | val loss 0.5988827944:
	--> training ...
	--> checkpointing ...

2024-10-10_02-43 : iter     435000 <=> epoch 0.23519839591003175 | train loss 0.6012566090 | val loss 0.5987583995:
	--> training ...
	--> checkpointing ...

2024-10-10_03-23 : iter     440000 <=> epoch 0.23790182574807808 | train loss 0.5997948050 | val loss 0.6009292006:
	--> training ...
	--> checkpointing ...

2024-10-10_04-04 : iter     445000 <=> epoch 0.24060525558612442 | train loss 0.6010241508 | val loss 0.6005124450:
	--> training ...
	--> checkpointing ...

2024-10-10_04-44 : iter     450000 <=> epoch 0.24330868542417078 | train loss 0.6002933383 | val loss 0.5997917056:
	--> training ...
	--> checkpointing ...

2024-10-10_05-25 : iter     455000 <=> epoch 0.2460121152622171 | train loss 0.6001941562 | val loss 0.5996221304:
	--> training ...
	--> checkpointing ...

2024-10-10_06-05 : iter     460000 <=> epoch 0.24871554510026345 | train loss 0.5999568105 | val loss 0.5984886289:
	--> training ...
	--> checkpointing ...

2024-10-10_06-45 : iter     465000 <=> epoch 0.2514189749383098 | train loss 0.5969600677 | val loss 0.5986857414:
	--> training ...
	--> checkpointing ...

2024-10-10_07-26 : iter     470000 <=> epoch 0.2541224047763561 | train loss 0.6005800962 | val loss 0.6012471318:
	--> training ...
	--> checkpointing ...

2024-10-10_08-06 : iter     475000 <=> epoch 0.25682583461440245 | train loss 0.6002525687 | val loss 0.5987226367:
	--> training ...
	--> checkpointing ...

2024-10-10_08-47 : iter     480000 <=> epoch 0.25952926445244884 | train loss 0.5989079475 | val loss 0.5996795297:
	--> training ...
	--> checkpointing ...

2024-10-10_09-27 : iter     485000 <=> epoch 0.26223269429049517 | train loss 0.5996345282 | val loss 0.5994164348:
	--> training ...
	--> checkpointing ...

2024-10-10_10-08 : iter     490000 <=> epoch 0.2649361241285415 | train loss 0.5968365073 | val loss 0.5978420973:
	--> training ...
	--> checkpointing ...

2024-10-10_10-48 : iter     495000 <=> epoch 0.26763955396658784 | train loss 0.5990049243 | val loss 0.5979443192:
	--> training ...
	--> checkpointing ...

2024-10-10_11-29 : iter     500000 <=> epoch 0.2703429838046342 | train loss 0.5980208516 | val loss 0.5979360938:
	--> training ...
	--> checkpointing ...

2024-10-10_12-09 : iter     505000 <=> epoch 0.2730464136426805 | train loss 0.5974450111 | val loss 0.5978483558:
	--> training ...
	--> checkpointing ...

2024-10-10_12-50 : iter     510000 <=> epoch 0.27574984348072684 | train loss 0.5987620950 | val loss 0.5980297923:
	--> training ...
	--> checkpointing ...

2024-10-10_13-30 : iter     515000 <=> epoch 0.27845327331877323 | train loss 0.5968533158 | val loss 0.5967501998:
	--> training ...
	--> checkpointing ...

2024-10-10_14-11 : iter     520000 <=> epoch 0.28115670315681957 | train loss 0.5984804034 | val loss 0.5993117690:
	--> training ...
	--> checkpointing ...

2024-10-10_14-51 : iter     525000 <=> epoch 0.2838601329948659 | train loss 0.5966401100 | val loss 0.5978693366:
	--> training ...
	--> checkpointing ...

2024-10-10_15-31 : iter     530000 <=> epoch 0.28656356283291223 | train loss 0.5995177627 | val loss 0.5979440212:
	--> training ...
	--> checkpointing ...

2024-10-10_16-12 : iter     535000 <=> epoch 0.28926699267095857 | train loss 0.5982427001 | val loss 0.5971093178:
	--> training ...
	--> checkpointing ...

2024-10-10_16-53 : iter     540000 <=> epoch 0.2919704225090049 | train loss 0.5983110070 | val loss 0.5964837074:
	--> training ...
	--> checkpointing ...

2024-10-10_17-33 : iter     545000 <=> epoch 0.29467385234705123 | train loss 0.5977500081 | val loss 0.5980889201:
	--> training ...
	--> checkpointing ...

2024-10-10_18-14 : iter     550000 <=> epoch 0.2973772821850976 | train loss 0.5974837542 | val loss 0.5974301696:
	--> training ...
	--> checkpointing ...

2024-10-10_18-54 : iter     555000 <=> epoch 0.30008071202314396 | train loss 0.5981751084 | val loss 0.5961654782:
	--> training ...
	--> checkpointing ...

2024-10-10_19-35 : iter     560000 <=> epoch 0.3027841418611903 | train loss 0.5976406336 | val loss 0.5965753198:
	--> training ...
	--> checkpointing ...

2024-10-10_20-16 : iter     565000 <=> epoch 0.3054875716992366 | train loss 0.5964521766 | val loss 0.5972388983:
	--> training ...
	--> checkpointing ...

2024-10-10_20-56 : iter     570000 <=> epoch 0.30819100153728296 | train loss 0.5963248014 | val loss 0.5957391858:
	--> training ...
	--> checkpointing ...

2024-10-10_21-37 : iter     575000 <=> epoch 0.3108944313753293 | train loss 0.5971818566 | val loss 0.5963762999:
	--> training ...
	--> checkpointing ...

2024-10-10_22-17 : iter     580000 <=> epoch 0.31359786121337563 | train loss 0.5957370996 | val loss 0.5972191691:
	--> training ...
	--> checkpointing ...

2024-10-10_22-58 : iter     585000 <=> epoch 0.316301291051422 | train loss 0.5943499804 | val loss 0.5954361558:
	--> training ...
	--> checkpointing ...

2024-10-10_23-39 : iter     590000 <=> epoch 0.31900472088946835 | train loss 0.5964570045 | val loss 0.5974382162:
	--> training ...
	--> checkpointing ...

2024-10-11_00-20 : iter     595000 <=> epoch 0.3217081507275147 | train loss 0.5961727500 | val loss 0.5965068340:
	--> training ...
	--> checkpointing ...

2024-10-11_01-00 : iter     600000 <=> epoch 0.324411580565561 | train loss 0.5971017480 | val loss 0.5960671306:
	--> training ...
	--> checkpointing ...

2024-10-11_01-41 : iter     605000 <=> epoch 0.32711501040360735 | train loss 0.5974303484 | val loss 0.5967476368:
	--> training ...
	--> checkpointing ...

2024-10-11_02-22 : iter     610000 <=> epoch 0.3298184402416537 | train loss 0.5950209498 | val loss 0.5956258178:
	--> training ...
	--> checkpointing ...

2024-10-11_03-02 : iter     615000 <=> epoch 0.3325218700797 | train loss 0.5948207378 | val loss 0.5957775712:
	--> training ...
	--> checkpointing ...

2024-10-11_03-43 : iter     620000 <=> epoch 0.3352252999177464 | train loss 0.5960474014 | val loss 0.5969862938:
	--> training ...
	--> checkpointing ...

2024-10-11_04-24 : iter     625000 <=> epoch 0.33792872975579274 | train loss 0.5951964855 | val loss 0.5955904722:
	--> training ...
	--> checkpointing ...

2024-10-11_05-04 : iter     630000 <=> epoch 0.3406321595938391 | train loss 0.5954549313 | val loss 0.5957402587:
	--> training ...
	--> checkpointing ...

2024-10-11_05-45 : iter     635000 <=> epoch 0.3433355894318854 | train loss 0.5954477191 | val loss 0.5951105356:
	--> training ...
	--> checkpointing ...

2024-10-11_06-25 : iter     640000 <=> epoch 0.34603901926993175 | train loss 0.5957785249 | val loss 0.5962612033:
	--> training ...
	--> checkpointing ...

2024-10-11_07-06 : iter     645000 <=> epoch 0.3487424491079781 | train loss 0.5959178209 | val loss 0.5944752693:
	--> training ...
	--> checkpointing ...

2024-10-11_07-47 : iter     650000 <=> epoch 0.3514458789460244 | train loss 0.5958311558 | val loss 0.5963360667:
	--> training ...
	--> checkpointing ...

2024-10-11_08-28 : iter     655000 <=> epoch 0.3541493087840708 | train loss 0.5967759490 | val loss 0.5938674808:
	--> training ...
	--> checkpointing ...

2024-10-11_09-08 : iter     660000 <=> epoch 0.35685273862211714 | train loss 0.5952686071 | val loss 0.5968178511:
	--> training ...
	--> checkpointing ...

2024-10-11_09-49 : iter     665000 <=> epoch 0.35955616846016347 | train loss 0.5941711068 | val loss 0.5955267549:
	--> training ...
	--> checkpointing ...

2024-10-11_10-29 : iter     670000 <=> epoch 0.3622595982982098 | train loss 0.5957121253 | val loss 0.5950407386:
	--> training ...
	--> checkpointing ...

2024-10-11_11-10 : iter     675000 <=> epoch 0.36496302813625614 | train loss 0.5973402262 | val loss 0.5963842273:
	--> training ...
	--> checkpointing ...

2024-10-11_11-51 : iter     680000 <=> epoch 0.3676664579743025 | train loss 0.5951027870 | val loss 0.5962088108:
	--> training ...
	--> checkpointing ...

2024-10-11_12-31 : iter     685000 <=> epoch 0.3703698878123488 | train loss 0.5940918326 | val loss 0.5954661965:
	--> training ...
	--> checkpointing ...

2024-10-11_13-12 : iter     690000 <=> epoch 0.3730733176503952 | train loss 0.5951836109 | val loss 0.5946699381:
	--> training ...
	--> checkpointing ...

2024-10-11_13-53 : iter     695000 <=> epoch 0.37577674748844153 | train loss 0.5966683626 | val loss 0.5948259234:
	--> training ...
	--> checkpointing ...

2024-10-11_14-33 : iter     700000 <=> epoch 0.37848017732648787 | train loss 0.5946314335 | val loss 0.5947931409:
	--> training ...
	--> checkpointing ...

2024-10-11_15-14 : iter     705000 <=> epoch 0.3811836071645342 | train loss 0.5933400393 | val loss 0.5935904980:
	--> training ...
	--> checkpointing ...

2024-10-11_15-54 : iter     710000 <=> epoch 0.38388703700258053 | train loss 0.5942730308 | val loss 0.5940021276:
	--> training ...
	--> checkpointing ...

2024-10-11_16-35 : iter     715000 <=> epoch 0.38659046684062687 | train loss 0.5941869617 | val loss 0.5945881009:
	--> training ...
	--> checkpointing ...

2024-10-11_17-16 : iter     720000 <=> epoch 0.3892938966786732 | train loss 0.5949977636 | val loss 0.5941623449:
	--> training ...
	--> checkpointing ...

2024-10-11_17-56 : iter     725000 <=> epoch 0.3919973265167196 | train loss 0.5941637158 | val loss 0.5944901109:
	--> training ...
	--> checkpointing ...

2024-10-11_18-37 : iter     730000 <=> epoch 0.3947007563547659 | train loss 0.5933146477 | val loss 0.5944838524:
	--> training ...
	--> checkpointing ...

2024-10-11_19-18 : iter     735000 <=> epoch 0.39740418619281226 | train loss 0.5964230895 | val loss 0.5945431590:
	--> training ...
	--> checkpointing ...

2024-10-11_19-58 : iter     740000 <=> epoch 0.4001076160308586 | train loss 0.5954949856 | val loss 0.5947555900:
	--> training ...
	--> checkpointing ...

2024-10-11_20-39 : iter     745000 <=> epoch 0.4028110458689049 | train loss 0.5954031348 | val loss 0.5937807560:
	--> training ...
	--> checkpointing ...

2024-10-11_21-20 : iter     750000 <=> epoch 0.40551447570695126 | train loss 0.5940498710 | val loss 0.5945573449:
	--> training ...
	--> checkpointing ...

2024-10-11_22-00 : iter     755000 <=> epoch 0.4082179055449976 | train loss 0.5941624641 | val loss 0.5939599872:
	--> training ...
	--> checkpointing ...

2024-10-11_22-41 : iter     760000 <=> epoch 0.410921335383044 | train loss 0.5943356156 | val loss 0.5945942998:
	--> training ...
	--> checkpointing ...

2024-10-11_23-21 : iter     765000 <=> epoch 0.4136247652210903 | train loss 0.5937492847 | val loss 0.5937160254:
	--> training ...
	--> checkpointing ...

2024-10-12_00-02 : iter     770000 <=> epoch 0.41632819505913665 | train loss 0.5944037437 | val loss 0.5947534442:
	--> training ...
	--> checkpointing ...

2024-10-12_00-43 : iter     775000 <=> epoch 0.419031624897183 | train loss 0.5952368379 | val loss 0.5953962803:
	--> training ...
	--> checkpointing ...

2024-10-12_01-23 : iter     780000 <=> epoch 0.4217350547352293 | train loss 0.5931933522 | val loss 0.5939117670:
	--> training ...
	--> checkpointing ...

2024-10-12_02-04 : iter     785000 <=> epoch 0.42443848457327565 | train loss 0.5940831900 | val loss 0.5931097269:
	--> training ...
	--> checkpointing ...

2024-10-12_02-44 : iter     790000 <=> epoch 0.427141914411322 | train loss 0.5952599645 | val loss 0.5953420997:
	--> training ...
	--> checkpointing ...

2024-10-12_03-25 : iter     795000 <=> epoch 0.4298453442493684 | train loss 0.5942388177 | val loss 0.5933674574:
	--> training ...
	--> checkpointing ...

2024-10-12_04-05 : iter     800000 <=> epoch 0.4325487740874147 | train loss 0.5943571329 | val loss 0.5936780572:
	--> training ...
	--> checkpointing ...

2024-10-12_04-46 : iter     805000 <=> epoch 0.43525220392546105 | train loss 0.5930343270 | val loss 0.5937185884:
	--> training ...
	--> checkpointing ...

2024-10-12_05-26 : iter     810000 <=> epoch 0.4379556337635074 | train loss 0.5939958096 | val loss 0.5939955711:
	--> training ...
	--> checkpointing ...

2024-10-12_06-06 : iter     815000 <=> epoch 0.4406590636015537 | train loss 0.5937973261 | val loss 0.5936434865:
	--> training ...
	--> checkpointing ...

2024-10-12_06-47 : iter     820000 <=> epoch 0.44336249343960005 | train loss 0.5949953794 | val loss 0.5932577252:
	--> training ...
	--> checkpointing ...

2024-10-12_07-27 : iter     825000 <=> epoch 0.4460659232776464 | train loss 0.5937433839 | val loss 0.5945566297:
	--> training ...
	--> checkpointing ...

2024-10-12_08-08 : iter     830000 <=> epoch 0.44876935311569277 | train loss 0.5939975977 | val loss 0.5938577652:
	--> training ...
	--> checkpointing ...

2024-10-12_08-48 : iter     835000 <=> epoch 0.4514727829537391 | train loss 0.5943571925 | val loss 0.5945214629:
	--> training ...
	--> checkpointing ...

2024-10-12_09-29 : iter     840000 <=> epoch 0.45417621279178544 | train loss 0.5947481394 | val loss 0.5944174528:
	--> training ...
	--> checkpointing ...

2024-10-12_10-09 : iter     845000 <=> epoch 0.4568796426298318 | train loss 0.5931476355 | val loss 0.5931245685:
	--> training ...
	--> checkpointing ...

2024-10-12_10-50 : iter     850000 <=> epoch 0.4595830724678781 | train loss 0.5934746861 | val loss 0.5941414833:
	--> training ...
	--> checkpointing ...

2024-10-12_11-30 : iter     855000 <=> epoch 0.46228650230592444 | train loss 0.5949446559 | val loss 0.5941674709:
	--> training ...
	--> checkpointing ...

2024-10-12_12-11 : iter     860000 <=> epoch 0.4649899321439708 | train loss 0.5952033401 | val loss 0.5931817889:
	--> training ...
	--> checkpointing ...

2024-10-12_12-51 : iter     865000 <=> epoch 0.46769336198201716 | train loss 0.5929819942 | val loss 0.5932022333:
	--> training ...
	--> checkpointing ...

2024-10-12_13-32 : iter     870000 <=> epoch 0.4703967918200635 | train loss 0.5949994326 | val loss 0.5943417549:
	--> training ...
	--> checkpointing ...

2024-10-12_14-12 : iter     875000 <=> epoch 0.47310022165810983 | train loss 0.5927054286 | val loss 0.5943747759:
	--> training ...
	--> checkpointing ...

2024-10-12_14-53 : iter     880000 <=> epoch 0.47580365149615617 | train loss 0.5935077667 | val loss 0.5931032300:
	--> training ...
	--> checkpointing ...

2024-10-12_15-33 : iter     885000 <=> epoch 0.4785070813342025 | train loss 0.5935564041 | val loss 0.5933751464:
	--> training ...
	--> checkpointing ...

2024-10-12_16-14 : iter     890000 <=> epoch 0.48121051117224883 | train loss 0.5926671028 | val loss 0.5927172899:
	--> training ...
	--> checkpointing ...

2024-10-12_16-54 : iter     895000 <=> epoch 0.48391394101029517 | train loss 0.5942937732 | val loss 0.5933452249:
	--> training ...
	--> checkpointing ...

2024-10-12_17-35 : iter     900000 <=> epoch 0.48661737084834156 | train loss 0.5935378671 | val loss 0.5928952694:
	--> training ...
	--> checkpointing ...

2024-10-12_18-15 : iter     905000 <=> epoch 0.4893208006863879 | train loss 0.5924277306 | val loss 0.5922020674:
	--> training ...
	--> checkpointing ...

2024-10-12_18-56 : iter     910000 <=> epoch 0.4920242305244342 | train loss 0.5925970078 | val loss 0.5927996039:
	--> training ...
	--> checkpointing ...

2024-10-12_19-36 : iter     915000 <=> epoch 0.49472766036248056 | train loss 0.5916290283 | val loss 0.5924477577:
	--> training ...
	--> checkpointing ...

2024-10-12_20-17 : iter     920000 <=> epoch 0.4974310902005269 | train loss 0.5919731855 | val loss 0.5934466124:
	--> training ...
	--> checkpointing ...

2024-10-12_20-57 : iter     925000 <=> epoch 0.5001345200385733 | train loss 0.5931001902 | val loss 0.5918297172:
	--> training ...
	--> checkpointing ...

2024-10-12_21-37 : iter     930000 <=> epoch 0.5028379498766196 | train loss 0.5929313302 | val loss 0.5949357152:
	--> training ...
	--> checkpointing ...

2024-10-12_22-18 : iter     935000 <=> epoch 0.505541379714666 | train loss 0.5923468471 | val loss 0.5937018394:
	--> training ...
	--> checkpointing ...

2024-10-12_22-58 : iter     940000 <=> epoch 0.5082448095527122 | train loss 0.5918887258 | val loss 0.5943366289:
	--> training ...
	--> checkpointing ...

2024-10-12_23-39 : iter     945000 <=> epoch 0.5109482393907586 | train loss 0.5937390327 | val loss 0.5940355659:
	--> training ...
	--> checkpointing ...

2024-10-13_00-19 : iter     950000 <=> epoch 0.5136516692288049 | train loss 0.5938323736 | val loss 0.5927897692:
	--> training ...
	--> checkpointing ...

2024-10-13_01-00 : iter     955000 <=> epoch 0.5163550990668513 | train loss 0.5933195353 | val loss 0.5937317014:
	--> training ...
	--> checkpointing ...

2024-10-13_01-40 : iter     960000 <=> epoch 0.5190585289048977 | train loss 0.5931044221 | val loss 0.5929121971:
	--> training ...
	--> checkpointing ...

2024-10-13_02-21 : iter     965000 <=> epoch 0.521761958742944 | train loss 0.5918198228 | val loss 0.5926684737:
	--> training ...
	--> checkpointing ...

2024-10-13_03-01 : iter     970000 <=> epoch 0.5244653885809903 | train loss 0.5921422243 | val loss 0.5918101072:
	--> training ...
	--> checkpointing ...

2024-10-13_03-41 : iter     975000 <=> epoch 0.5271688184190366 | train loss 0.5938369036 | val loss 0.5929142237:
	--> training ...
	--> checkpointing ...

2024-10-13_04-22 : iter     980000 <=> epoch 0.529872248257083 | train loss 0.5916752219 | val loss 0.5925075412:
	--> training ...
	--> checkpointing ...

2024-10-13_05-02 : iter     985000 <=> epoch 0.5325756780951293 | train loss 0.5929911733 | val loss 0.5920020938:
	--> training ...
	--> checkpointing ...

2024-10-13_05-43 : iter     990000 <=> epoch 0.5352791079331757 | train loss 0.5918056965 | val loss 0.5932068229:
	--> training ...
	--> checkpointing ...

2024-10-13_06-23 : iter     995000 <=> epoch 0.5379825377712221 | train loss 0.5930657983 | val loss 0.5934578776:
	--> training ...
	--> checkpointing ...

2024-10-13_07-04 : iter    1000000 <=> epoch 0.5406859676092683 | train loss 0.5949631929 | val loss 0.5935502648:
	--> training ...
	--> checkpointing ...

2024-10-13_07-44 : iter    1005000 <=> epoch 0.5433893974473147 | train loss 0.5915297866 | val loss 0.5910298228:
	--> training ...
	--> checkpointing ...

2024-10-13_08-25 : iter    1010000 <=> epoch 0.546092827285361 | train loss 0.5925692320 | val loss 0.5923073888:
	--> training ...
	--> checkpointing ...

2024-10-13_09-05 : iter    1015000 <=> epoch 0.5487962571234074 | train loss 0.5906861424 | val loss 0.5921906829:
	--> training ...
	--> checkpointing ...

2024-10-13_09-46 : iter    1020000 <=> epoch 0.5514996869614537 | train loss 0.5936029553 | val loss 0.5927640200:
	--> training ...
	--> checkpointing ...

2024-10-13_10-26 : iter    1025000 <=> epoch 0.5542031167995001 | train loss 0.5930607319 | val loss 0.5931112766:
	--> training ...
	--> checkpointing ...

2024-10-13_11-07 : iter    1030000 <=> epoch 0.5569065466375465 | train loss 0.5923820734 | val loss 0.5926824808:
	--> training ...
	--> checkpointing ...

2024-10-13_11-47 : iter    1035000 <=> epoch 0.5596099764755927 | train loss 0.5913074017 | val loss 0.5931855440:
	--> training ...
	--> checkpointing ...

2024-10-13_12-28 : iter    1040000 <=> epoch 0.5623134063136391 | train loss 0.5918106437 | val loss 0.5932510495:
	--> training ...
	--> checkpointing ...

2024-10-13_13-08 : iter    1045000 <=> epoch 0.5650168361516854 | train loss 0.5914734602 | val loss 0.5923340917:
	--> training ...
	--> checkpointing ...

2024-10-13_13-49 : iter    1050000 <=> epoch 0.5677202659897318 | train loss 0.5929059982 | val loss 0.5920803547:
	--> training ...
	--> checkpointing ...

2024-10-13_14-29 : iter    1055000 <=> epoch 0.5704236958277781 | train loss 0.5926564932 | val loss 0.5922623277:
	--> training ...
	--> checkpointing ...

2024-10-13_15-10 : iter    1060000 <=> epoch 0.5731271256658245 | train loss 0.5924820304 | val loss 0.5907562971:
	--> training ...
	--> checkpointing ...

2024-10-13_15-50 : iter    1065000 <=> epoch 0.5758305555038709 | train loss 0.5926454067 | val loss 0.5927076340:
	--> training ...
	--> checkpointing ...

2024-10-13_16-31 : iter    1070000 <=> epoch 0.5785339853419171 | train loss 0.5935369730 | val loss 0.5926337242:
	--> training ...
	--> checkpointing ...

2024-10-13_17-11 : iter    1075000 <=> epoch 0.5812374151799635 | train loss 0.5934692621 | val loss 0.5929496884:
	--> training ...
	--> checkpointing ...

2024-10-13_17-52 : iter    1080000 <=> epoch 0.5839408450180098 | train loss 0.5926586390 | val loss 0.5914711952:
	--> training ...
	--> checkpointing ...

2024-10-13_18-32 : iter    1085000 <=> epoch 0.5866442748560562 | train loss 0.5912904143 | val loss 0.5927361846:
	--> training ...
	--> checkpointing ...

2024-10-13_19-12 : iter    1090000 <=> epoch 0.5893477046941025 | train loss 0.5923137665 | val loss 0.5907844901:
	--> training ...
	--> checkpointing ...

2024-10-13_19-53 : iter    1095000 <=> epoch 0.5920511345321489 | train loss 0.5949398875 | val loss 0.5938447714:
	--> training ...
	--> checkpointing ...

2024-10-13_20-33 : iter    1100000 <=> epoch 0.5947545643701952 | train loss 0.5924484730 | val loss 0.5930835605:
	--> training ...
	--> checkpointing ...

2024-10-13_21-14 : iter    1105000 <=> epoch 0.5974579942082415 | train loss 0.5923931599 | val loss 0.5919442177:
	--> training ...
	--> checkpointing ...

2024-10-13_21-54 : iter    1110000 <=> epoch 0.6001614240462879 | train loss 0.5928463340 | val loss 0.5929167867:
	--> training ...
	--> checkpointing ...

2024-10-13_22-35 : iter    1115000 <=> epoch 0.6028648538843342 | train loss 0.5916686058 | val loss 0.5916801095:
	--> training ...
	--> checkpointing ...

2024-10-13_23-15 : iter    1120000 <=> epoch 0.6055682837223806 | train loss 0.5919763446 | val loss 0.5921466351:
	--> training ...
	--> checkpointing ...

2024-10-13_23-55 : iter    1125000 <=> epoch 0.6082717135604269 | train loss 0.5926207304 | val loss 0.5911963582:
	--> training ...
	--> checkpointing ...

2024-10-14_00-36 : iter    1130000 <=> epoch 0.6109751433984733 | train loss 0.5916899443 | val loss 0.5920720696:
	--> training ...
	--> checkpointing ...

2024-10-14_01-16 : iter    1135000 <=> epoch 0.6136785732365196 | train loss 0.5915222168 | val loss 0.5924483538:
	--> training ...
	--> checkpointing ...

2024-10-14_01-57 : iter    1140000 <=> epoch 0.6163820030745659 | train loss 0.5921271443 | val loss 0.5909976959:
	--> training ...
	--> checkpointing ...

2024-10-14_02-37 : iter    1145000 <=> epoch 0.6190854329126123 | train loss 0.5919955969 | val loss 0.5928207636:
	--> training ...
	--> checkpointing ...

2024-10-14_03-18 : iter    1150000 <=> epoch 0.6217888627506586 | train loss 0.5924245119 | val loss 0.5926834941:
	--> training ...
	--> checkpointing ...

2024-10-14_03-58 : iter    1155000 <=> epoch 0.624492292588705 | train loss 0.5930274725 | val loss 0.5926309228:
	--> training ...
	--> checkpointing ...

2024-10-14_04-38 : iter    1160000 <=> epoch 0.6271957224267513 | train loss 0.5899681449 | val loss 0.5922090411:
	--> training ...
	--> checkpointing ...

2024-10-14_05-19 : iter    1165000 <=> epoch 0.6298991522647976 | train loss 0.5921129584 | val loss 0.5935162306:
	--> training ...
	--> checkpointing ...

2024-10-14_05-59 : iter    1170000 <=> epoch 0.632602582102844 | train loss 0.5923851132 | val loss 0.5910565257:
	--> training ...
	--> checkpointing ...

2024-10-14_06-40 : iter    1175000 <=> epoch 0.6353060119408903 | train loss 0.5923402905 | val loss 0.5929129720:
	--> training ...
	--> checkpointing ...

2024-10-14_07-20 : iter    1180000 <=> epoch 0.6380094417789367 | train loss 0.5916458964 | val loss 0.5919154882:
	--> training ...
	--> checkpointing ...

2024-10-14_08-00 : iter    1185000 <=> epoch 0.640712871616983 | train loss 0.5921246409 | val loss 0.5911464691:
	--> training ...
	--> checkpointing ...

2024-10-14_08-41 : iter    1190000 <=> epoch 0.6434163014550294 | train loss 0.5914850831 | val loss 0.5910804272:
	--> training ...
	--> checkpointing ...

2024-10-14_09-21 : iter    1195000 <=> epoch 0.6461197312930756 | train loss 0.5920942426 | val loss 0.5918335915:
	--> training ...
	--> checkpointing ...

2024-10-14_10-02 : iter    1200000 <=> epoch 0.648823161131122 | train loss 0.5898495913 | val loss 0.5908780098:
	--> training ...
	--> checkpointing ...

2024-10-14_10-42 : iter    1205000 <=> epoch 0.6515265909691684 | train loss 0.5914864540 | val loss 0.5910052061:
	--> training ...
	--> checkpointing ...

2024-10-14_11-23 : iter    1210000 <=> epoch 0.6542300208072147 | train loss 0.5917453766 | val loss 0.5913473964:
	--> training ...
	--> checkpointing ...

2024-10-14_12-03 : iter    1215000 <=> epoch 0.6569334506452611 | train loss 0.5919052958 | val loss 0.5924226642:
	--> training ...
	--> checkpointing ...

2024-10-14_12-43 : iter    1220000 <=> epoch 0.6596368804833074 | train loss 0.5931547880 | val loss 0.5913378000:
	--> training ...
	--> checkpointing ...

2024-10-14_13-24 : iter    1225000 <=> epoch 0.6623403103213538 | train loss 0.5929093957 | val loss 0.5924853086:
	--> training ...
	--> checkpointing ...

2024-10-14_14-04 : iter    1230000 <=> epoch 0.6650437401594 | train loss 0.5919132233 | val loss 0.5920785666:
	--> training ...
	--> checkpointing ...

2024-10-14_14-45 : iter    1235000 <=> epoch 0.6677471699974464 | train loss 0.5899111032 | val loss 0.5911955833:
	--> training ...
	--> checkpointing ...

2024-10-14_15-25 : iter    1240000 <=> epoch 0.6704505998354928 | train loss 0.5907052755 | val loss 0.5922170877:
	--> training ...
	--> checkpointing ...

2024-10-14_16-06 : iter    1245000 <=> epoch 0.6731540296735391 | train loss 0.5919247270 | val loss 0.5916833878:
	--> training ...
	--> checkpointing ...

2024-10-14_16-46 : iter    1250000 <=> epoch 0.6758574595115855 | train loss 0.5922122598 | val loss 0.5918442607:
	--> training ...
	--> checkpointing ...

2024-10-14_17-27 : iter    1255000 <=> epoch 0.6785608893496318 | train loss 0.5906543136 | val loss 0.5916590095:
	--> training ...
	--> checkpointing ...

2024-10-14_18-07 : iter    1260000 <=> epoch 0.6812643191876782 | train loss 0.5917395949 | val loss 0.5917824507:
	--> training ...
	--> checkpointing ...

2024-10-14_18-47 : iter    1265000 <=> epoch 0.6839677490257244 | train loss 0.5928679705 | val loss 0.5915810466:
	--> training ...
	--> checkpointing ...

2024-10-14_19-28 : iter    1270000 <=> epoch 0.6866711788637708 | train loss 0.5921012163 | val loss 0.5929124355:
	--> training ...
	--> checkpointing ...

2024-10-14_20-08 : iter    1275000 <=> epoch 0.6893746087018172 | train loss 0.5909281373 | val loss 0.5911701918:
	--> training ...
	--> checkpointing ...

2024-10-14_20-49 : iter    1280000 <=> epoch 0.6920780385398635 | train loss 0.5905075669 | val loss 0.5909519792:
	--> training ...
	--> checkpointing ...

2024-10-14_21-29 : iter    1285000 <=> epoch 0.6947814683779099 | train loss 0.5910584331 | val loss 0.5914884210:
	--> training ...
	--> checkpointing ...

2024-10-14_22-10 : iter    1290000 <=> epoch 0.6974848982159562 | train loss 0.5917782784 | val loss 0.5916809440:
	--> training ...
	--> checkpointing ...

2024-10-14_22-50 : iter    1295000 <=> epoch 0.7001883280540026 | train loss 0.5920262337 | val loss 0.5910576582:
	--> training ...
	--> checkpointing ...

2024-10-14_23-31 : iter    1300000 <=> epoch 0.7028917578920488 | train loss 0.5912577510 | val loss 0.5901907682:
	--> training ...
	--> checkpointing ...

2024-10-15_00-11 : iter    1305000 <=> epoch 0.7055951877300952 | train loss 0.5915275216 | val loss 0.5916901827:
	--> training ...
	--> checkpointing ...

2024-10-15_00-51 : iter    1310000 <=> epoch 0.7082986175681416 | train loss 0.5933737755 | val loss 0.5920577645:
	--> training ...
	--> checkpointing ...

2024-10-15_01-32 : iter    1315000 <=> epoch 0.7110020474061879 | train loss 0.5918519497 | val loss 0.5918433070:
	--> training ...
	--> checkpointing ...

2024-10-15_02-12 : iter    1320000 <=> epoch 0.7137054772442343 | train loss 0.5922644138 | val loss 0.5913664103:
	--> training ...
	--> checkpointing ...

2024-10-15_02-53 : iter    1325000 <=> epoch 0.7164089070822806 | train loss 0.5922463536 | val loss 0.5911611915:
	--> training ...
	--> checkpointing ...

2024-10-15_03-33 : iter    1330000 <=> epoch 0.7191123369203269 | train loss 0.5923638940 | val loss 0.5918387175:
	--> training ...
	--> checkpointing ...

2024-10-15_04-14 : iter    1335000 <=> epoch 0.7218157667583732 | train loss 0.5921667814 | val loss 0.5910193920:
	--> training ...
	--> checkpointing ...

2024-10-15_04-54 : iter    1340000 <=> epoch 0.7245191965964196 | train loss 0.5904759765 | val loss 0.5912403464:
	--> training ...
	--> checkpointing ...

2024-10-15_05-35 : iter    1345000 <=> epoch 0.727222626434466 | train loss 0.5931008458 | val loss 0.5913833380:
	--> training ...
	--> checkpointing ...

2024-10-15_06-15 : iter    1350000 <=> epoch 0.7299260562725123 | train loss 0.5921394825 | val loss 0.5923597217:
	--> training ...
	--> checkpointing ...

2024-10-15_06-55 : iter    1355000 <=> epoch 0.7326294861105587 | train loss 0.5915631056 | val loss 0.5926498175:
	--> training ...
	--> checkpointing ...

2024-10-15_07-36 : iter    1360000 <=> epoch 0.735332915948605 | train loss 0.5934120417 | val loss 0.5929243565:
	--> training ...
	--> checkpointing ...

2024-10-15_08-16 : iter    1365000 <=> epoch 0.7380363457866513 | train loss 0.5935528278 | val loss 0.5916082859:
	--> training ...
	--> checkpointing ...

2024-10-15_08-57 : iter    1370000 <=> epoch 0.7407397756246976 | train loss 0.5910249949 | val loss 0.5916967392:
	--> training ...
	--> checkpointing ...

2024-10-15_09-37 : iter    1375000 <=> epoch 0.743443205462744 | train loss 0.5912892222 | val loss 0.5908477306:
	--> training ...
	--> checkpointing ...

2024-10-15_10-17 : iter    1380000 <=> epoch 0.7461466353007904 | train loss 0.5912743211 | val loss 0.5909337401:
	--> training ...
	--> checkpointing ...

2024-10-15_10-58 : iter    1385000 <=> epoch 0.7488500651388367 | train loss 0.5909602642 | val loss 0.5903220177:
	--> training ...
	--> checkpointing ...

2024-10-15_11-38 : iter    1390000 <=> epoch 0.7515534949768831 | train loss 0.5906993747 | val loss 0.5908324122:
	--> training ...
	--> checkpointing ...

2024-10-15_12-19 : iter    1395000 <=> epoch 0.7542569248149293 | train loss 0.5899119973 | val loss 0.5914168954:
	--> training ...
	--> checkpointing ...

2024-10-15_12-59 : iter    1400000 <=> epoch 0.7569603546529757 | train loss 0.5926072001 | val loss 0.5920811892:
	--> training ...
	--> checkpointing ...

2024-10-15_13-40 : iter    1405000 <=> epoch 0.759663784491022 | train loss 0.5909550190 | val loss 0.5920124650:
	--> training ...
	--> checkpointing ...

2024-10-15_14-20 : iter    1410000 <=> epoch 0.7623672143290684 | train loss 0.5909337997 | val loss 0.5919434428:
	--> training ...
	--> checkpointing ...

2024-10-15_15-01 : iter    1415000 <=> epoch 0.7650706441671148 | train loss 0.5917468667 | val loss 0.5917654037:
	--> training ...
	--> checkpointing ...

2024-10-15_15-41 : iter    1420000 <=> epoch 0.7677740740051611 | train loss 0.5918384194 | val loss 0.5909323096:
	--> training ...
	--> checkpointing ...

2024-10-15_16-21 : iter    1425000 <=> epoch 0.7704775038432075 | train loss 0.5911797881 | val loss 0.5909108520:
	--> training ...
	--> checkpointing ...

2024-10-15_17-02 : iter    1430000 <=> epoch 0.7731809336812537 | train loss 0.5904260278 | val loss 0.5909661651:
	--> training ...
	--> checkpointing ...

2024-10-15_17-42 : iter    1435000 <=> epoch 0.7758843635193001 | train loss 0.5923425555 | val loss 0.5921954513:
	--> training ...
	--> checkpointing ...

2024-10-15_18-23 : iter    1440000 <=> epoch 0.7785877933573464 | train loss 0.5906884670 | val loss 0.5905930400:
	--> training ...
	--> checkpointing ...

2024-10-15_19-03 : iter    1445000 <=> epoch 0.7812912231953928 | train loss 0.5930107236 | val loss 0.5915089250:
	--> training ...
	--> checkpointing ...

2024-10-15_19-44 : iter    1450000 <=> epoch 0.7839946530334392 | train loss 0.5911421180 | val loss 0.5902512074:
	--> training ...
	--> checkpointing ...

2024-10-15_20-24 : iter    1455000 <=> epoch 0.7866980828714855 | train loss 0.5922651291 | val loss 0.5910742283:
	--> training ...
	--> checkpointing ...

2024-10-15_21-05 : iter    1460000 <=> epoch 0.7894015127095318 | train loss 0.5910089612 | val loss 0.5926460028:
	--> training ...
	--> checkpointing ...

2024-10-15_21-45 : iter    1465000 <=> epoch 0.7921049425475781 | train loss 0.5911157131 | val loss 0.5907894969:
	--> training ...
	--> checkpointing ...

2024-10-15_22-26 : iter    1470000 <=> epoch 0.7948083723856245 | train loss 0.5915356874 | val loss 0.5906751752:
	--> training ...
	--> checkpointing ...

2024-10-15_23-06 : iter    1475000 <=> epoch 0.7975118022236708 | train loss 0.5916134119 | val loss 0.5917146206:
	--> training ...
	--> checkpointing ...

2024-10-15_23-46 : iter    1480000 <=> epoch 0.8002152320617172 | train loss 0.5926114917 | val loss 0.5933391452:
	--> training ...
	--> checkpointing ...

2024-10-16_00-27 : iter    1485000 <=> epoch 0.8029186618997636 | train loss 0.5905973315 | val loss 0.5920788050:
	--> training ...
	--> checkpointing ...

2024-10-16_01-07 : iter    1490000 <=> epoch 0.8056220917378099 | train loss 0.5914540887 | val loss 0.5917814970:
	--> training ...
	--> checkpointing ...

2024-10-16_01-48 : iter    1495000 <=> epoch 0.8083255215758562 | train loss 0.5910912156 | val loss 0.5908529162:
	--> training ...
	--> checkpointing ...

2024-10-16_02-28 : iter    1500000 <=> epoch 0.8110289514139025 | train loss 0.5920755267 | val loss 0.5910634995:
	--> training ...
	--> checkpointing ...

2024-10-16_03-09 : iter    1505000 <=> epoch 0.8137323812519489 | train loss 0.5910799503 | val loss 0.5907455087:
	--> training ...
	--> checkpointing ...

2024-10-16_03-49 : iter    1510000 <=> epoch 0.8164358110899952 | train loss 0.5918084979 | val loss 0.5917828083:
	--> training ...
	--> checkpointing ...

2024-10-16_04-30 : iter    1515000 <=> epoch 0.8191392409280416 | train loss 0.5922200084 | val loss 0.5919520855:
	--> training ...
	--> checkpointing ...

2024-10-16_05-10 : iter    1520000 <=> epoch 0.821842670766088 | train loss 0.5926147103 | val loss 0.5917180181:
	--> training ...
	--> checkpointing ...

2024-10-16_05-51 : iter    1525000 <=> epoch 0.8245461006041342 | train loss 0.5918291807 | val loss 0.5910586119:
	--> training ...
	--> checkpointing ...

2024-10-16_06-31 : iter    1530000 <=> epoch 0.8272495304421806 | train loss 0.5913996696 | val loss 0.5915108919:
	--> training ...
	--> checkpointing ...

2024-10-16_07-12 : iter    1535000 <=> epoch 0.8299529602802269 | train loss 0.5898800492 | val loss 0.5931079388:
	--> training ...
	--> checkpointing ...

2024-10-16_07-52 : iter    1540000 <=> epoch 0.8326563901182733 | train loss 0.5915089846 | val loss 0.5916301608:
	--> training ...
	--> checkpointing ...

2024-10-16_08-33 : iter    1545000 <=> epoch 0.8353598199563196 | train loss 0.5911527276 | val loss 0.5921952128:
	--> training ...
	--> checkpointing ...

2024-10-16_09-13 : iter    1550000 <=> epoch 0.838063249794366 | train loss 0.5912305117 | val loss 0.5904862881:
	--> training ...
	--> checkpointing ...

2024-10-16_09-54 : iter    1555000 <=> epoch 0.8407666796324124 | train loss 0.5895459056 | val loss 0.5914382339:
	--> training ...
	--> checkpointing ...

2024-10-16_10-34 : iter    1560000 <=> epoch 0.8434701094704586 | train loss 0.5905774832 | val loss 0.5893299580:
	--> training ...
	--> checkpointing ...

2024-10-16_11-15 : iter    1565000 <=> epoch 0.846173539308505 | train loss 0.5919476151 | val loss 0.5904996991:
	--> training ...
	--> checkpointing ...

2024-10-16_11-55 : iter    1570000 <=> epoch 0.8488769691465513 | train loss 0.5918708444 | val loss 0.5903244019:
	--> training ...
	--> checkpointing ...

2024-10-16_12-36 : iter    1575000 <=> epoch 0.8515803989845977 | train loss 0.5919050574 | val loss 0.5914182067:
	--> training ...
	--> checkpointing ...

2024-10-16_13-16 : iter    1580000 <=> epoch 0.854283828822644 | train loss 0.5922684073 | val loss 0.5912585258:
	--> training ...
	--> checkpointing ...

2024-10-16_13-57 : iter    1585000 <=> epoch 0.8569872586606904 | train loss 0.5905672312 | val loss 0.5919868946:
	--> training ...
	--> checkpointing ...

2024-10-16_14-37 : iter    1590000 <=> epoch 0.8596906884987368 | train loss 0.5902878046 | val loss 0.5918916464:
	--> training ...
	--> checkpointing ...

2024-10-16_15-17 : iter    1595000 <=> epoch 0.862394118336783 | train loss 0.5900840163 | val loss 0.5916244984:
	--> training ...
	--> checkpointing ...

2024-10-16_15-58 : iter    1600000 <=> epoch 0.8650975481748294 | train loss 0.5917832851 | val loss 0.5909017920:
	--> training ...
	--> checkpointing ...

2024-10-16_16-38 : iter    1605000 <=> epoch 0.8678009780128757 | train loss 0.5915821195 | val loss 0.5903974771:
	--> training ...
	--> checkpointing ...

2024-10-16_17-19 : iter    1610000 <=> epoch 0.8705044078509221 | train loss 0.5919803977 | val loss 0.5905921459:
	--> training ...
	--> checkpointing ...

2024-10-16_17-59 : iter    1615000 <=> epoch 0.8732078376889684 | train loss 0.5888748169 | val loss 0.5902159214:
	--> training ...
	--> checkpointing ...

2024-10-16_18-40 : iter    1620000 <=> epoch 0.8759112675270148 | train loss 0.5901986361 | val loss 0.5901469588:
	--> training ...
	--> checkpointing ...

2024-10-16_19-20 : iter    1625000 <=> epoch 0.8786146973650611 | train loss 0.5921196342 | val loss 0.5910188556:
	--> training ...
	--> checkpointing ...

2024-10-16_20-01 : iter    1630000 <=> epoch 0.8813181272031074 | train loss 0.5910407305 | val loss 0.5917983651:
	--> training ...
	--> checkpointing ...

2024-10-16_20-41 : iter    1635000 <=> epoch 0.8840215570411538 | train loss 0.5910308361 | val loss 0.5903657675:
	--> training ...
	--> checkpointing ...

2024-10-16_21-22 : iter    1640000 <=> epoch 0.8867249868792001 | train loss 0.5921221375 | val loss 0.5896478295:
	--> training ...
	--> checkpointing ...

2024-10-16_22-02 : iter    1645000 <=> epoch 0.8894284167172465 | train loss 0.5914655924 | val loss 0.5902283788:
	--> training ...
	--> checkpointing ...

2024-10-16_22-42 : iter    1650000 <=> epoch 0.8921318465552928 | train loss 0.5915563703 | val loss 0.5933032632:
	--> training ...
	--> checkpointing ...

2024-10-16_23-23 : iter    1655000 <=> epoch 0.8948352763933392 | train loss 0.5912002921 | val loss 0.5906396508:
	--> training ...
	--> checkpointing ...

2024-10-17_00-03 : iter    1660000 <=> epoch 0.8975387062313855 | train loss 0.5896883011 | val loss 0.5913377404:
	--> training ...
	--> checkpointing ...

2024-10-17_00-44 : iter    1665000 <=> epoch 0.9002421360694318 | train loss 0.5906727314 | val loss 0.5901564956:
	--> training ...
	--> checkpointing ...

2024-10-17_01-24 : iter    1670000 <=> epoch 0.9029455659074782 | train loss 0.5916619897 | val loss 0.5891016126:
	--> training ...
	--> checkpointing ...

2024-10-17_02-05 : iter    1675000 <=> epoch 0.9056489957455245 | train loss 0.5908914208 | val loss 0.5925894380:
	--> training ...
	--> checkpointing ...

2024-10-17_02-45 : iter    1680000 <=> epoch 0.9083524255835709 | train loss 0.5931673646 | val loss 0.5922577977:
	--> training ...
	--> checkpointing ...

2024-10-17_03-26 : iter    1685000 <=> epoch 0.9110558554216172 | train loss 0.5901812911 | val loss 0.5880330205:
	--> training ...
	--> checkpointing ...

2024-10-17_04-06 : iter    1690000 <=> epoch 0.9137592852596635 | train loss 0.5902222395 | val loss 0.5908483267:
	--> training ...
	--> checkpointing ...

2024-10-17_04-47 : iter    1695000 <=> epoch 0.9164627150977099 | train loss 0.5906189680 | val loss 0.5907549262:
	--> training ...
	--> checkpointing ...

2024-10-17_05-27 : iter    1700000 <=> epoch 0.9191661449357562 | train loss 0.5903976560 | val loss 0.5908293724:
	--> training ...
	--> checkpointing ...

2024-10-17_06-08 : iter    1705000 <=> epoch 0.9218695747738026 | train loss 0.5908778310 | val loss 0.5909157991:
	--> training ...
	--> checkpointing ...

2024-10-17_06-48 : iter    1710000 <=> epoch 0.9245730046118489 | train loss 0.5918933153 | val loss 0.5890249610:
	--> training ...
	--> checkpointing ...

2024-10-17_07-29 : iter    1715000 <=> epoch 0.9272764344498953 | train loss 0.5897304416 | val loss 0.5907326937:
	--> training ...
	--> checkpointing ...

2024-10-17_08-09 : iter    1720000 <=> epoch 0.9299798642879415 | train loss 0.5899020433 | val loss 0.5909477472:
	--> training ...
	--> checkpointing ...

2024-10-17_08-49 : iter    1725000 <=> epoch 0.9326832941259879 | train loss 0.5908561349 | val loss 0.5917876959:
	--> training ...
